<!doctype html>
<html>
  <head>
    <title>Romy Mi Luo's Homepage</title>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="description" content="Mi Luo is at UT Austin.">
    <meta name="keywords" content="Mi Luo, romy luo, luomi">

    <meta property="og:type" content="website">
    <meta property="og:title" content="Mi Luo's Homepage">
    <meta property="og:site_name" content="Mi Luo's Homepage">
    <meta property="og:description" content="Mi Luo is at UT Austin.">
    <meta property="og:locale" content="default">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Mi Luo's Homepage">
    <meta name="twitter:description" content="Mi Luo is at UT Austin.">


    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP" crossorigin="anonymous">
    <link rel="stylesheet" href="stylesheets/academicons/css/academicons.min.css"/>


  </head>
  <body>
    <div class="wrapper">
      <header>
        <center>
        <a href="#" class="image avatar"><img src="images/avatar.jpg" alt="" onContextMenu="return false" /></a>
        <h1><strong>(Romy) Mi LUO</strong><br></h1>
            University of Texas at Austin<br>
            romyluo7 (at) gmail.com<br>
            [<a href="https://scholar.google.com/citations?user=eL-xIlAAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Google Scholar</a>]
            <br>
        </center>
      </header>
      <section>
          <h1 id="biography"><a href="#biography" class="headerlink" title="biography"></a>About Me</h1>

              <p>I am a second-year PhD student at UT Austin, advised by <a href="https://www.cs.utexas.edu/users/grauman/" target="_blank" rel="noopener">Prof. Kristen Grauman</a> and <a href="https://users.ece.utexas.edu/~dimakis/index.html" target="_blank" rel="noopener">Prof. Alex Dimakis</a>. My research lies in <strong>Machine Learning</strong> and <strong>Computer Vision</strong>, specifically in the following topics:</p>
              <ul>
              <li> First-person "egocentric" vision
              <li> Deep generative models
              <li> Designing new architectures for real-world machine learning system
              <li> Learning generalizable and transferrable representations
              </ul>

          <h1 id="publications"><a href="#publications" class="headerlink" title="publications"></a>Publications</h1>

              <ul>
              <li><papertitle>Put Myself in Your Shoes: Lifting the Egocentric Perspective from Exocentric Videos</papertitle>
                <br>
                <strong>Mi Luo</strong>, Zihui Xue, Alex Dimakis, Kristen Grauman
                <br>
                <strong>arXiv, 2024</strong>.
                <br>
                [<a href="https://arxiv.org/pdf/2403.06351.pdf" target="_blank" rel="noopener">PDF</a>]
                </ul>

        
              <ul>
              <li><papertitle>Ego-Exo4D: Understanding Skilled Human Activity from First-and Third-Person Perspectives</papertitle>
                <br>
                Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra Malik, …, <strong>Mi Luo</strong>, …, Pablo Arbelaez, Gedas Bertasius, David Crandall, Dima Damen, Jakob Engel, Giovanni Maria Farinella, Antonino Furnari, Bernard Ghanem, Judy Hoffman, C. V. Jawahar, Richard Newcombe, Hyun Soo Park, James M. Rehg, Yoichi Sato, Manolis Savva, Jianbo Shi, Mike Zheng Shou, Michael Wray
                <br>
                In IEEE/CVF Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2024</strong>.
                <br>
                [<a href="https://arxiv.org/pdf/2311.18259.pdf" target="_blank" rel="noopener">PDF</a>][<a href="https://ego-exo4d-data.org/" target="_blank" rel="noopener">Project</a>][<a href="https://ai.meta.com/blog/ego-exo4d-video-learning-perception/" target="_blank" rel="noopener">Overview</a>][<a href="https://www.youtube.com/watch?v=GdooXEBAnI8" target="_blank" rel="noopener">Video</a>]
                </ul>
        
              <ul>
              <li><papertitle>MetaFormer Baselines for Vision</papertitle>
                <br>
                Weihao Yu, Chenyang Si, Pan Zhou, <strong>Mi Luo</strong>, Yichen Zhou, Jiashi Feng, Shuicheng Yan, Xinchao Wang
                <br>
                IEEE Transactions on Pattern Analysis and Machine Intelligence, <strong>T-PAMI 2023</strong>.
                <br>
                [<a href="https://arxiv.org/pdf/2210.13452.pdf" target="_blank" rel="noopener">PDF</a>][<a href="https://github.com/sail-sg/metaformer" target="_blank" rel="noopener">Project</a>]
                </ul>
        
              <ul>
              <li><papertitle>MetaFormer is Actually What You Need for Vision</papertitle>
                <br>
                Weihao Yu, <strong>Mi Luo</strong>, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi Feng, Shuicheng Yan
                <br>
                In IEEE/CVF Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2022</strong>. (<strong>Oral</strong>)
                <br>
                [<a href="https://arxiv.org/pdf/2111.11418.pdf" target="_blank" rel="noopener">PDF</a>][<a href="https://github.com/sail-sg/poolformer" target="_blank" rel="noopener">Project</a>]
                <br>
                </ul>
        
              <ul>
              <li><papertitle>Architecture Personalization in Resource-constrained Federated Learning</papertitle>
                <br>
                <strong>Mi Luo</strong>, Fei Chen, Zhenguo Li, Jiashi Feng
                <br>
                In <strong><a href="https://neurips2021workshopfl.github.io/NFFL-2021/index.html" target="_blank" rel="noopener">NFFL Workshop</a></strong>, <strong>NeurIPS 2021</strong>. (<strong>Selected as outstanding paper, acceptance rate: 9%</strong>)
                <br>
                [<a href="images/Workshop-version_Camera ready.pdf" target="_blank" rel="noopener">PDF</a>]                
                <br>
              </ul>
        
        
              <ul>
              <li><papertitle>No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data</papertitle>
                <br>
                <strong>Mi Luo</strong>, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, Jiashi Feng
                <br>
                In Advances in Neural Information Processing Systems, <strong>NeurIPS 2021</strong>.	
                <br>
                [<a href="https://arxiv.org/abs/2106.05001" target="_blank" rel="noopener">PDF</a>]
                <br>
              </ul>
        
              <ul>
              <li><papertitle>MetaSelector: Meta-Learning for Recommendation with User-Level Adaptive Model Selection</papertitle>
                <br>
                <strong>Mi Luo</strong>, Fei Chen, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Jiashi Feng, Zhenguo Li
                <br>
                In Proceedings of The Web Conference, <strong>WWW 2020</strong>.
                <br>
                [<a href="https://dl.acm.org/doi/fullHtml/10.1145/3366423.3379999" target="_blank" rel="noopener">PDF</a>]
              </li>
              </ul>

              <ul>
              <li><papertitle>Federated Meta-Learning with Fast Convergence and Efficient Communication</papertitle>
                <br>
                Fei Chen, <strong>Mi Luo</strong>, Zhenhua Dong, Zhenguo Li, Xiuqiang He
                <br>
                <strong>arXiv, 2019</strong>.
                <br>
                [<a href="https://arxiv.org/abs/1802.07876" target="_blank" rel="noopener">PDF</a>]
                </ul>

        <h1 id="research"><a href="#research" class="headerlink" title="research"></a>Research Experiences</h1>
              <ul>
              <li><p style="float:right">Singapore, Sep 2021 - Apr 2022</p> <strong>SEA AI Lab (SAIL)</strong>
                <br>
                Research Intern, Advisor: <a href="https://scholar.google.com.hk/citations?user=DNuiPHwAAAAJ&hl=zh-CN" target="_blank" rel="noopener">Prof. Shuicheng Yan</a>
              </ul>

              <ul>
              <li><p style="float:right">Singapore, Aug 2020 - Aug 2021</p> <strong>National University of Singapore </strong>
                <br>
                Research Assistant, Advisor: <a href="https://scholar.google.com/citations?user=Q8iay0gAAAAJ&hl=en" target="_blank" rel="noopener">Prof. Jiashi Feng</a>
              </ul>
        
              <ul>
              <li><p style="float:right">Hong Kong, May 2019 - Oct 2019</p><strong>Huawei Noah’s Ark Lab</strong>
                <br>
                Research Intern, Advisor: <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&hl=en" target="_blank" rel="noopener">Dr. Zhenguo Li</a>
              </ul>

        <h1 id="service"><a href="#service" class="headerlink" title="service"></a>Professional Service</h1>
              <ul>
              <li><strong>Conference Reviewer</strong>: CVPR 2023 - 2024, ECCV 2024, ICCV 2023, ACCV 2024, NeurIPS 2023, ICLR 2024, ICML 2024, AISTATS 2022 - 2024
                <br>
              <li><strong>Journal Reviewer</strong>: IEEE Transactions on Knowledge and Data Engineering (TKDE)
              <br>
              <li><strong>Teaching Assistant</strong>: EE2211 (Introduction to Machine Learning), CG3207 (Computer Architecture)
              </ul>
        
          <br>

      </section>

      <footer>
          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=b29eb8&w=a&t=n&d=_RtXcKM0NfeqVtamIco4ZifjHtbkiQqlat-tseipi9k&co=ffffff&cmo=bac8db&cmn=a15c9a&ct=808080'></script>
      </footer>
    </div>
  </body>
</html>
